---
title: "Classification Example"
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Classification Example}
output:
  knitr:::html_vignette:
    toc: yes
---
  
```{r ex_setup, include=FALSE}
knitr::opts_chunk$set(
  digits = 3,
  collapse = TRUE,
  comment = "#>"
)
options(digits = 3)
library(parsnip)
library(tibble)
library(ggplot2)

theme_set(theme_bw())
```

To demonstrate `parsnip` for classification models, the credit data will be used. 

```{r credit-split}
library(tidymodels)

data(credit_data)

set.seed(7075)
data_split <- initial_split(credit_data, strata = "Status", p = 0.75)

credit_train <- training(data_split)
credit_test  <- testing(data_split)
```

A single hidden layer neural network will be used to predict a person's credit status. To do so, the columns of the predictor matrix should be numeric and on a common scale. `recipes` will be used to do so.  

```{r credit-proc}
credit_rec <- 
  recipe(Status ~ ., data = credit_train) %>%
  step_knnimpute(Home, Job, Marital, Income, Assets, Debt) %>%
  step_dummy(all_nominal(), -Status) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep(training = credit_train, retain = TRUE)

# juice() will be used to get the processed training set back

test_normalized <- bake(credit_rec, new_data = credit_test, all_predictors())
```

`keras` will be used to fit a model with 5 hidden units and uses a 10% dropout rate to regularize the model. At each training iteration (aka epoch) a random 20% of the data will be used to measure the cross-entropy of the model. 

```{r credit-nnet}
set.seed(57974)
nnet_fit <-
  mlp(epochs = 100, hidden_units = 5, dropout = 0.1) %>%
  # Also set engine-specific arguments: 
  set_engine("keras", verbose = 0, validation_split = .20) %>%
  fit(Status ~ ., data = juice(credit_rec))

nnet_fit
```

In `parsnip`, the `predict` function can be used:.  


```{r credit-perf}
test_results <- 
  credit_test %>%
  select(Status) %>%
  as_tibble() %>%
  mutate(
    nnet_class = predict(nnet_fit, new_data = test_normalized) %>% 
      pull(.pred_class),
    nnet_prob  = predict(nnet_fit, new_data = test_normalized, type = "prob") %>% 
      pull(.pred_good)
  )

test_results %>% roc_auc(truth = Status, nnet_prob)
test_results %>% accuracy(truth = Status, nnet_class)
test_results %>% conf_mat(truth = Status, nnet_class)
```
