```{r}
#| child: aaa.Rmd
#| include: false
```

`r descr_models("rand_forest", "randomForest")`

## Tuning Parameters

```{r}
#| label: randomForest-param-info
#| echo: false
defaults <- 
  tibble::tibble(parsnip = c("mtry", "trees", "min_n"),
                 default = c("see below", "500L", "see below"))

param <-
  rand_forest() |> 
  set_engine("randomForest") |> 
  make_parameter_list(defaults)
```

This model has `r nrow(param)` tuning parameters:

```{r}
#| label: randomForest-param-list
#| echo: false
#| results: asis
param$item
```

`mtry` depends on the number of columns and the model mode. The default in [randomForest::randomForest()] is `floor(sqrt(ncol(x)))` for classification and `floor(ncol(x)/3)` for regression.

`min_n` depends on the mode. For regression, a value of 5 is the default. For classification, a value of 10 is used. 

## Translation from parsnip to the original package (regression)

```{r}
#| label: randomForest-reg
rand_forest(
  mtry = integer(1),
  trees = integer(1),
  min_n = integer(1)
) |>  
  set_engine("randomForest") |> 
  set_mode("regression") |> 
  translate()
```

`min_rows()` and `min_cols()` will adjust the number of neighbors if the chosen value if it is not consistent with the actual data dimensions.

## Translation from parsnip to the original package (classification)

```{r}
#| label: randomForest-cls
rand_forest(
  mtry = integer(1),
  trees = integer(1),
  min_n = integer(1)
) |> 
  set_engine("randomForest") |> 
  set_mode("classification") |> 
  translate()
```

## Preprocessing requirements

```{r}
#| child: template-tree-split-factors.Rmd
```

## Saving fitted model objects

```{r}
#| child: template-butcher.Rmd
```


## Examples 

The "Fitting and Predicting with parsnip" article contains [examples](https://parsnip.tidymodels.org/articles/articles/Examples.html#rand-forest-randomForest) for `rand_forest()` with the `"randomForest"` engine.

## References

 - Kuhn, M, and K Johnson. 2013. _Applied Predictive Modeling_. Springer.

