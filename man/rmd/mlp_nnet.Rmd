```{r}
#| child: aaa.Rmd
#| include: false
```

`r descr_models("mlp", "nnet")`

## Tuning Parameters

```{r}
#| label: nnet-param-info
#| echo: false
defaults <- 
  tibble::tibble(parsnip = c("hidden_units", "penalty", "epochs"),
                 default = c("none", "0.0", "100L"))

param <-
  mlp() |> 
  set_engine("nnet") |> 
  make_parameter_list(defaults)
```

This model has `r nrow(param)` tuning parameters:

```{r}
#| label: nnet-param-list
#| echo: false
#| results: asis
param$item
```

Note that, in [nnet::nnet()], the maximum number of parameters is an argument with a fairly low value of `maxit = 1000`. For some models, you may need to pass this value in via [set_engine()] so that the model does not fail. 


## Translation from parsnip to the original package (regression)

```{r}
#| label: nnet-reg
mlp(
  hidden_units = integer(1),
  penalty = double(1),
  epochs = integer(1)
) |>  
  set_engine("nnet") |> 
  set_mode("regression") |> 
  translate()
```

Note that parsnip automatically sets linear activation in the last layer. 

## Translation from parsnip to the original package (classification)

```{r}
#| label: nnet-cls
mlp(
  hidden_units = integer(1),
  penalty = double(1),
  epochs = integer(1)
) |> 
  set_engine("nnet") |> 
  set_mode("classification") |> 
  translate()
```


## Preprocessing requirements

```{r}
#| child: template-makes-dummies.Rmd
```

```{r}
#| child: template-same-scale.Rmd
```

## Case weights

```{r}
#| child: template-uses-case-weights.Rmd
```


## Prediction types

```{r}
#| label: predict-types

parsnip:::get_from_env("mlp_predict") |>
  dplyr::filter(engine == "nnet") |>
  dplyr::select(mode, type)

```

## Saving fitted model objects

```{r}
#| child: template-butcher.Rmd
```

## Examples 

The "Fitting and Predicting with parsnip" [article](https://www.tidymodels.org/learn/models/parsnip-predictions/) contains examples for `mlp()` with the `"nnet"` engine.

## References

 - Kuhn, M, and K Johnson. 2013. _Applied Predictive Modeling_. Springer.



