```{r, child = "setup.Rmd", include = FALSE}
```

`r descr_models("bart", "dbarts")`

## Tuning Parameters

```{r bart-param-info, echo = FALSE}
defaults <- 
  tibble::tibble(parsnip = c("trees", "prior_terminal_node_coef",
                             "prior_terminal_node_expo", "prior_outcome_range"),
                 default = c("200L", "0.95", "2.00", "2.00")
  )

param <-
 bart() %>% 
  set_engine("dbarts") %>% 
  set_mode("regression") %>% 
  tunable() %>% 
  dplyr::select(-source, -component, -component_id, parsnip = name) %>% 
  dplyr::mutate(
    dials = purrr::map(call_info, get_dials),
    label = purrr::map_chr(dials, ~ .x$label),
    type = purrr::map_chr(dials, ~ .x$type)
  ) %>% 
  dplyr::full_join(defaults, by = "parsnip") %>% 
  mutate(
    item = 
      glue::glue("- `{parsnip}`: {label} (type: {type}, default: {default})\n\n")
  )
```

This model has `r nrow(param)` tuning parameters:

```{r bart-param-list, echo = FALSE, results = "asis"}
param$item
```

## Important engine-specific options

Some relevant arguments that can be passed to `set_engine()`: 


## Translation from parsnip to the original package (classification)

```{r bart-cls}
bart(
  trees = integer(1),
  prior_terminal_node_coef = double(1),
  prior_terminal_node_expo = double(1),
  prior_outcome_range = double(1)
) %>% 
  set_engine("dbarts") %>% 
  set_mode("classification") %>% 
  translate()
```


## Translation from parsnip to the original package (regression)

```{r bart-reg}
bart(
  trees = integer(1),
  prior_terminal_node_coef = double(1),
  prior_terminal_node_expo = double(1),
  prior_outcome_range = double(1)
) %>% 
  set_engine("dbarts") %>% 
  set_mode("regression") %>% 
  translate()
```

## Preprocessing requirements

```{r child = "template-makes-dummies.Rmd"} 
```

[dbarts::bart()] will also convert the factors to indicators of the user does not create them first. 


## References

 - Chipman, George, McCulloch. "BART: Bayesian additive regression trees." _Ann. Appl. Stat._ 4 (1) 266 - 298, March 2010.
