```{r}
#| child: aaa.Rmd
#| include: false
```

`r descr_models("bart", "dbarts")`

## Tuning Parameters

```{r}
#| label: bart-param-info
#| echo: false
defaults <- 
  tibble::tibble(parsnip = c("trees", "prior_terminal_node_coef",
                             "prior_terminal_node_expo", "prior_outcome_range"),
                 default = c("200L", "0.95", "2.00", "2.00")
  )

param <-
 bart() |> 
  set_engine("dbarts") |> 
  set_mode("regression") |> 
  make_parameter_list(defaults)
```

This model has `r nrow(param)` tuning parameters:

```{r}
#| label: bart-param-list
#| echo: false
#| results: asis
param$item
```

Parsnip changes the default range for `trees` to `c(50, 500)`.

## Important engine-specific options

Some relevant arguments that can be passed to `set_engine()`: 

* `keepevery`, `n.thin`:	Every `keepevery` draw is kept to be returned to the user. Useful for "thinning" samples.

* `ntree`, `n.trees`: The number of trees in the sum-of-trees formulation.

* `ndpost`, `n.samples`: The number of posterior draws after burn in, `ndpost` / `keepevery` will actually be returned.

* `nskip`, `n.burn`: Number of MCMC iterations to be treated as burn in.

* `nchain`, `n.chains`: Integer specifying how many independent tree sets and fits should be calculated.

* `nthread`, `n.threads`: Integer specifying how many threads to use. Depending on the CPU architecture, using more than the number of chains can degrade performance for small/medium data sets. As such some calculations may be executed single threaded regardless.

* `combinechains`, `combineChains`: Logical; if `TRUE`, samples will be returned in arrays of dimensions equal to `nchain` times `ndpost` times number of observations.

## Translation from parsnip to the original package (classification)

```{r}
#| label: bart-cls
parsnip::bart(
  trees = integer(1),
  prior_terminal_node_coef = double(1),
  prior_terminal_node_expo = double(1),
  prior_outcome_range = double(1)
) |> 
  set_engine("dbarts") |> 
  set_mode("classification") |> 
  translate() |> 
  print_model_spec()
```


## Translation from parsnip to the original package (regression)

```{r}
#| label: bart-reg
parsnip::bart(
  trees = integer(1),
  prior_terminal_node_coef = double(1),
  prior_terminal_node_expo = double(1),
  prior_outcome_range = double(1)
) |> 
  set_engine("dbarts") |> 
  set_mode("regression") |> 
  translate()|> 
  print_model_spec()
```

## Preprocessing requirements

```{r} 
#| child: template-makes-dummies.Rmd
```

[dbarts::bart()] will also convert the factors to indicators if the user does not create them first. 


## References

 - Chipman, George, McCulloch. "BART: Bayesian additive regression trees." _Ann. Appl. Stat._ 4 (1) 266 - 298, March 2010.
