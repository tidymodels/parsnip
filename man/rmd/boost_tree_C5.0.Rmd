```{r, child = "setup.Rmd", include = FALSE}
```

`r descr_models("boost_tree", "C5.0")`

## Tuning Parameters

```{r C5.0-param-info, echo = FALSE}
defaults <- 
  tibble::tibble(parsnip = c("trees", "min_n", "sample_size"),
                 default = c("15L", "2L", "1.0"))

param <-
 boost_tree() %>% 
  set_engine("C5.0") %>% 
  set_mode("regression") %>% 
  tunable() %>% 
  dplyr::select(-source, -component, -component_id, parsnip = name) %>% 
  dplyr::mutate(
    dials = purrr::map(call_info, get_dials),
    label = purrr::map_chr(dials, ~ .x$label),
    type = purrr::map_chr(dials, ~ .x$type)
  ) %>% 
  dplyr::full_join(defaults, by = "parsnip") %>% 
  mutate(
    item = 
      glue::glue("- `{parsnip}`: {label} (type: {type}, default: {default})\n\n")
  )
```

This model has `r nrow(param)` tuning parameters:

```{r C5.0-param-list, echo = FALSE, results = "asis"}
param$item
```

The implementation of C5.0 limits the number of trees to be between 1 and 100.

## Translation from parsnip to the original package (classification)

```{r C5.0-cls}
boost_tree(trees = integer(), min_n = integer(), sample_size = numeric()) %>% 
  set_engine("C5.0") %>% 
  set_mode("classification") %>% 
  translate()
```

[C5.0_train()] is a wrapper around [C50::C5.0()] that makes it easier to run this model.

## Preprocessing requirements

```{r child = "template-tree-split-factors.Rmd"}
```

## Other details

### Early stopping

By default, early stopping is used. To use the complete set of boosting iterations, pass `earlyStopping = FALSE` to [set_engine()]. Also, it is unlikely that early stopping will occur if `sample_size = 1`.

## Examples 

The "Fitting and Predicting with parsnip" article contains [examples](https://parsnip.tidymodels.org/articles/articles/Examples.html#boost-tree-C5.0) for `boost_tree()` with the `"C5.0"` engine.

## References

-   Kuhn, M, and K Johnson. 2013. *Applied Predictive Modeling*. Springer.
