```{r, child = "setup.Rmd", include = FALSE}
```

`r descr_models("decision_tree", "rpart")`

## Tuning Parameters

```{r rpart-param-info, echo = FALSE}
defaults <- 
  tibble::tibble(parsnip = c("tree_depth", "min_n", "cost_complexity"),
                 default = c("30L", "2L", "0.01"))

param <-
 decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("regression") %>% 
  make_parameter_list(defaults)
```

This model has `r nrow(param)` tuning parameters:

```{r rpart-param-list, echo = FALSE, results = "asis"}
param$item
```

## Translation from parsnip to the original package (classification)

```{r rpart-cls}
decision_tree(tree_depth = integer(1), min_n = integer(1), cost_complexity = double(1)) %>% 
  set_engine("rpart") %>% 
  set_mode("classification") %>% 
  translate()
```


## Translation from parsnip to the original package (regression)

```{r rpart-reg}
decision_tree(tree_depth = integer(1), min_n = integer(1), cost_complexity = double(1)) %>% 
  set_engine("rpart") %>% 
  set_mode("regression") %>% 
  translate()
```

## Preprocessing requirements

```{r child = "template-tree-split-factors.Rmd"}
```

## Examples 

The "Fitting and Predicting with parsnip" article contains [examples](https://parsnip.tidymodels.org/articles/articles/Examples.html#decision-tree-rpart) for `decision_tree()` with the `"rpart"` engine.

## References

-   Kuhn, M, and K Johnson. 2013. *Applied Predictive Modeling*. Springer.

