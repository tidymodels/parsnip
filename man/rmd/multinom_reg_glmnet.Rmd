```{r}
#| child: aaa.Rmd
#| include: false
```

`r descr_models("multinom_reg", "glmnet")`

## Tuning Parameters

```{r}
#| label: glmnet-param-info
#| echo: false
defaults <- 
  tibble::tibble(parsnip = c("penalty", "mixture"),
                 default = c("see below", "1.0"))

param <-
multinom_reg() |> 
  set_engine("glmnet") |> 
  make_parameter_list(defaults)
```

This model has `r nrow(param)` tuning parameters:

```{r}
#| label: glmnet-param-list
#| echo: false
#| results: asis
param$item
```

The `penalty` parameter has no default and requires a single numeric value. For more details about this, and the `glmnet` model in general, see [glmnet-details]. As for `mixture`:

* `mixture = 1` specifies a pure lasso model,
* `mixture = 0`  specifies a ridge regression model, and
* `0 < mixture < 1` specifies an elastic net model, interpolating lasso and ridge.

## Translation from parsnip to the original package

```{r}
#| label: glmnet-cls
multinom_reg(penalty = double(1), mixture = double(1)) |> 
  set_engine("glmnet") |> 
  translate()
```

## Preprocessing requirements

```{r}
#| child: template-makes-dummies.Rmd
```

```{r}
#| child: template-same-scale.Rmd
```
By default, [glmnet::glmnet()] uses the argument `standardize = TRUE` to center and scale the data. 

## Examples 

The "Fitting and Predicting with parsnip" article contains [examples](https://parsnip.tidymodels.org/articles/articles/Examples.html#multinom-reg-glmnet) for `multinom_reg()` with the `"glmnet"` engine.

## Case weights

```{r}
#| child: template-uses-case-weights.Rmd
```

## Sparse Data

```{r}
#| child: template-uses-sparse-data.Rmd
```

## Saving fitted model objects

```{r}
#| child: template-butcher.Rmd
```

## References

 - Hastie, T, R Tibshirani, and M Wainwright. 2015. _Statistical Learning with Sparsity_. CRC Press.
 
 - Kuhn, M, and K Johnson. 2013. _Applied Predictive Modeling_. Springer.

