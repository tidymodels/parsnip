% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bart_bartMachine.R
\name{details_bart_bartMachine}
\alias{details_bart_bartMachine}
\title{Bayesian additive regression trees via bartMachine}
\description{
\code{\link[bartMachine:bartMachine]{bartMachine::bartMachine()}} creates an ensemble of tree-based model whose
training and assembly is determined using Bayesian analysis.
}
\details{
For this engine, there are multiple modes: classification and regression
\subsection{Tuning Parameters}{

This model has 4 tuning parameters:
\itemize{
\item \code{trees}: # Trees (type: integer, default: 50L)
\item \code{prior_terminal_node_coef}: Terminal Node Prior Coefficient (type:
double, default: 0.95)
\item \code{prior_terminal_node_expo}: Terminal Node Prior Exponent (type:
double, default: 2.00)
\item \code{prior_outcome_range}: Prior for Outcome Range (type: double,
default: 2.00)
}
}

\subsection{Important engine-specific options}{

Some relevant arguments that can be passed to \code{set_engine()}:
}

\subsection{Translation from parsnip to the original package (classification)}{\if{html}{\out{<div class="sourceCode r">}}\preformatted{bart(
  trees = integer(1),
  prior_terminal_node_coef = double(1),
  prior_terminal_node_expo = double(1),
  prior_outcome_range = double(1)
) \%>\% 
  set_engine("bartMachine") \%>\% 
  set_mode("classification") \%>\% 
  translate()
}\if{html}{\out{</div>}}\preformatted{## BART Model Specification (classification)
## 
## Main Arguments:
##   trees = integer(1)
##   prior_terminal_node_coef = double(1)
##   prior_terminal_node_expo = double(1)
##   prior_outcome_range = double(1)
## 
## Computational engine: bartMachine 
## 
## Model fit template:
## bartMachine::bartMachine(x = missing_arg(), y = missing_arg(), 
##     num_trees = integer(1), alpha = double(1), beta = double(1), 
##     k = double(1), verbose = FALSE, seed = sample.int(10^5, 1))
}
}

\subsection{Translation from parsnip to the original package (regression)}{\if{html}{\out{<div class="sourceCode r">}}\preformatted{bart(
  trees = integer(1),
  prior_terminal_node_coef = double(1),
  prior_terminal_node_expo = double(1),
  prior_outcome_range = double(1)
) \%>\% 
  set_engine("bartMachine") \%>\% 
  set_mode("regression") \%>\% 
  translate()
}\if{html}{\out{</div>}}\preformatted{## BART Model Specification (regression)
## 
## Main Arguments:
##   trees = integer(1)
##   prior_terminal_node_coef = double(1)
##   prior_terminal_node_expo = double(1)
##   prior_outcome_range = double(1)
## 
## Computational engine: bartMachine 
## 
## Model fit template:
## bartMachine::bartMachine(x = missing_arg(), y = missing_arg(), 
##     num_trees = integer(1), alpha = double(1), beta = double(1), 
##     k = double(1), verbose = FALSE, seed = sample.int(10^5, 1))
}
}

\subsection{Preprocessing requirements}{

Factor/categorical predictors need to be converted to numeric values
(e.g., dummy or indicator variables) for this engine. When using the
formula method via
\code{\link[=fit.model_spec]{fit.model_spec()}}, parsnip will
convert factor columns to indicators.
}

\subsection{Other details}{

For prediction, the \code{"bartMachine"} engine can compute posterior
intervals analogous to confidence and prediction intervals. In these
instances, the units are the original outcome and when
\code{std_error = TRUE}, the standard deviation of the posterior distribution
(or posterior predictive distribution as appropriate) is returned.
}

\subsection{Examples}{

The “Fitting and Predicting with parsnip” article contains
\href{https://parsnip.tidymodels.org/articles/articles/Examples.html#bart-bartMachine}{examples}
for \code{bart()} with the \code{"bartMachine"} engine.
}

\subsection{References}{
\itemize{
\item Chipman, George, McCulloch. “BART: Bayesian additive regression
trees.” \emph{Ann. Appl. Stat.} 4 (1) 266 - 298, March 2010.
\item Bleich (2016). “bartMachine: Machine Learning with Bayesian Additive
Regression Trees.” \emph{Journal of Statistical Software}, 70(4), 1-40.
doi: 10.18637/jss.v070.i04.
}
}
}
\keyword{internal}
